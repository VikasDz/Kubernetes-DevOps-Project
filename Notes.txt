Container Orchestration
(Auto Scaling ,Auto Healing Feature of K8S)
In K8S, We Can Setup the kubernetes in Three Ways:
1.Mini Kube (For Small Projects But Not Applicable on Production Level)
2.Kubeadm (Open Source Tool Which Allows You Setup Kubernetes and Use in Production As Well) (2 Server Needs Master and Workers Nodes)
3.Manage K8 Cluster
  =>AWS (EKS)
  =>Azure (AKS)
  =>GCP (GKE)
4.KIND (Kubernetes in Docker)

Cluster => cluster is a group of servers and other resources that act like a single system and enable high availability, load balancing and parallel processing.

============Setup Kubernetes Cluster Using Kubeadm===========================================================
---------------------------------------- Kubeadm Installation ------------------------------------------ 

-------------------------------------- Both Master & Worker Node ---------------------------------------
# using 'sudo su' is not a good practice.
sudo apt update
sudo apt-get install -y apt-transport-https ca-certificates curl
sudo apt install docker.io -y

sudo systemctl enable --now docker # enable and start in single command.

# Adding GPG keys.
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

# Add the repository to the sourcelist.
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list

sudo apt update 
sudo apt install -y kubeadm=1.28.1-1.1 kubelet=1.28.1-1.1 kubectl=1.28.1-1.1 -y


# To connect with cluster execute above commands on master node and worker node respectively
--------------------------------------------- Master Node -------------------------------------------------- 
sudo su
kubeadm init

# To start using your cluster, you need to run the following as a regular user:
  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

# Alternatively, if you are the root user, you can run:
  export KUBECONFIG=/etc/kubernetes/admin.conf
  
kubectl apply -f https://github.com/weaveworks/weave/releases/download/v2.8.1/weave-daemonset-k8s.yaml

kubeadm token create --print-join-command
  

------------------------------------------- Worker Node ------------------------------------------------ 
sudo su
kubeadm reset pre-flight checks
-----> Paste the Join command on worker node and append `--v=5` at end

#To verify cluster connection  
open 6443 inBound Rules in EC2 Machine
---------------------------------------on Master Node-----------------------------------------

kubectl get nodes 


# worker
# kubeadm join 172.31.84.66:6443 --token n4tfb4.grmew1s1unug0get     --discovery-token-ca-cert-hash sha256:c3fda2eaf5960bed4320d8175dc6a73b1556795b1b7f5aadc07642ed85c51069 --v=5
# kubeadm reset pre-flight checks
# kubeadm token create --print-join-command
# kubectl label node ip-172-31-20-246 node-role.kubernetes.io/worker=worker
# kubectl label nodes ip-172-31-92-99 kubernetes.io/role=worker
# kubectl config set-context $(kubectl config current-context) --namespace=dev


============Some Commands:===================================================================================
kubectl get nodes (Check How Many Nodes are Connected with Master Node)

kubectl run nginx --image=nginx --restart=Always (For Create Pods in Worker Nodes)

kubectl get pods (Check all Pods are Connected with Worker Node)

docker kill container_id (Kill the container in Worker Node but When we Check the POds in Master Node Then It will Auto start Again Thats Why we Call is Auto Scaling and Auto Healing)

===========================Topics============================================================================
Pods
    Smallest Unit Contanier
    ManifestFile(Configuration File)
    Yml File(Yet Another Markup Language)
    Everything in K8S in yml file
    Check YmlFile Folder.
    Make Directory in Master Node for Create pod.yml file
    =>mkdir project
    =>cd project
    =>vim pod.yml
    Command for Apply the pod.yml file on worker Cluster (kubectl apply -f pod.yml)
    Check Pods are Available (kubectl get pods)
    Delete the pod (kubectl delete -f pod.yml)

Deployments
    Deployment provides declarative updates for Pods and ReplicaSets.
    It is place where we can create our pods template
    Manifest file check yaml Folder
    Using Label Pods Belongs to Namespace Group (Check deployment.yml)
    For Auto Scaling we Create Replica
    After Deployment.yml File Completed (kubectl apply -f deployment.yml)
    Run This => kubctl get pods -n=my-application
    You Can scale Replica Using This Command
    => kubctl scale deployment microservices-flask-pod --replicas=10 -n=my-application (Then You Have Create 10 Replicas of Pods)
    kubctl get pods -n=my-application
    
Services
    In Kubernetes, a Service is a method for exposing a network application that is running as one or more Pods in your cluster.
    Service.yml Checks in K8S Folder
    Service are Three Types:
    NodePort,ClusterIP,LoadBalancer
    We Use NodePort
    Check File For Better Understanding
    vim service.yml (After Writing Your yml file)
    kubectl apply -f service.yml
    kubectl get svc -n=my-application
    Update Your Inbound Rule  8001 port with AnyOne and Hit the Worker Node IP With Port 8001
    
Secrets and Config Maps
    ConfigMaps is Place Where we store Some Data or Store Configuration Data.
    Create configmap.yml and secret.yml
    kubectl apply -f configmap.yml and secret.yml  Both Check Folder for Better Understanding.
    Check env in Deployment.
    using base64 decoded we can easily decrypt the Secret Data Password.
    cmd => echo "your_password" | base64
    Using Service.yml we can Expose our This Pod.

Ingress

=============================================================================================================
Always Use t2.medium for K8S Cluster
Assignment=> Deploy a Microservice Project on K8S.


Note : 
    If You want to Go docker Inside Container Then Use (sudo docker exec -it container_id bash) in Worker Node
    Test Your Pod or Docker Container Which is Working Fine or Not (curl -L http://127.0.0.1:8000) in Worker Node
    Namespace is a logical group where we define which pods are belong to which group. => in Master Node
    => kubectl get namespaces
    => kubectl get pods -n=kube-system (Where You get all the services of Master Node) 
    Create own Namespace
    => kubectl create namespace my-application
    => vim pod.yml
    apiVersion: v1
    kind: Pod
    metadata:
        name: microservices-flask-pod
        namespace: my-application
    spec:
    containers:
        - name: microservices-flask
        image: vikashkumar97/microservices-flask-api:latest
        ports:
        - containerPort: 8001
    =>kubctl apply -f pod.yml
    =>kubctl get pods
    =>kubctl get pods -n=my-application
        You Get Your Pods
    




